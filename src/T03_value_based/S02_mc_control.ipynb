{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d0b382c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from gridworld import GridworldEnv\n",
    "\n",
    "env = GridworldEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "06cf1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy in the Limit with Infinite Exploration (GLIE)\n",
    "def GLIE(env, discount_factor=1.0, episode_count=100):\n",
    "    \"\"\"\n",
    "    Find optimal policy given an environment.\n",
    "\n",
    "    Args:\n",
    "        env: OpenAI env. In model free setup you have no access to env.P,\n",
    "             transition dynamics of the environment.\n",
    "             use step(a) to take an action and receive a tuple\n",
    "             of (s', r, done, info)\n",
    "             env.nS is number of states in the environment.\n",
    "             env.nA is number of actions in the environment.\n",
    "        episode_count: Number of episodes:\n",
    "        discount_factor: Gamma discount factor.\n",
    "\n",
    "    Returns:\n",
    "        Vector of length env.nS representing the value function.\n",
    "        policy:[S, A] shaped matrix representing the policy. Random in our case\n",
    "\n",
    "    \"\"\"\n",
    "    # Start with (all 0) state value array and state-action matrix.\n",
    "    # also initialize visit count to zero for the state-action visit count.\n",
    "    V = np.zeros(env.nS)\n",
    "    N = np.zeros((env.nS, env.nA))\n",
    "    Q = np.zeros((env.nS, env.nA))\n",
    "    # random policy\n",
    "    policy = [np.random.randint(env.nA) for _ in range(env.nS)]\n",
    "    k = 1\n",
    "    eps = 1\n",
    "\n",
    "    def argmax_a(arr):\n",
    "        \"\"\"\n",
    "        Return idx of max element in an array.\n",
    "        Break ties uniformly.\n",
    "        \"\"\"\n",
    "        max_idx = []\n",
    "        max_val = float(\"-inf\")\n",
    "        for idx, elem in enumerate(arr):\n",
    "            if elem == max_val:\n",
    "                max_idx.append(idx)\n",
    "            elif elem > max_val:\n",
    "                max_idx = [idx]\n",
    "                max_val = elem\n",
    "        return np.random.choice(max_idx)\n",
    "\n",
    "    def get_action(state):\n",
    "        if np.random.random() < eps:\n",
    "            return np.random.choice(env.nA)\n",
    "        else:\n",
    "            return argmax_a(Q[state])\n",
    "\n",
    "    # run multiple episodes\n",
    "    while k <= episode_count:\n",
    "        # collect samples for one episode\n",
    "        episode_states = []\n",
    "        episode_actions = []\n",
    "        episode_returns = []\n",
    "        state, _ = env.reset()\n",
    "        episode_states.append(state)\n",
    "        while True:\n",
    "            action = get_action(state)\n",
    "            episode_actions.append(action)\n",
    "            (state, reward, done, _, _) = env.step(action)\n",
    "            episode_returns.append(reward)\n",
    "            if not done:\n",
    "                episode_states.append(state)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # update state-action values\n",
    "        G = 0\n",
    "        count = len(episode_states)\n",
    "        for t in range(count - 1, -1, -1):\n",
    "            s, a, r = episode_states[t], episode_actions[t], episode_returns[t]\n",
    "            G = discount_factor * G + r\n",
    "            N[s, a] += 1\n",
    "            Q[s, a] = Q[s, a] + 1 / N[s, a] * (G - Q[s, a])\n",
    "\n",
    "        # Update policy and optimal value\n",
    "        k = k + 1\n",
    "        eps = 1 / k\n",
    "        # uncomment \"if\" to have higher exploration initially and\n",
    "        # then let epislon decay after 5000 episodes\n",
    "        # if k <=100:\n",
    "        #    eps = 0.02\n",
    "\n",
    "        for s in range(env.nS):\n",
    "            best_action = argmax_a(Q[s])\n",
    "            policy[s] = best_action\n",
    "            V[s] = Q[s, best_action]\n",
    "\n",
    "    return np.array(V), np.array(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3bf186e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom print to show state values inside the grid\n",
    "def grid_print(V):\n",
    "    ax = sns.heatmap(\n",
    "        V.reshape(env.shape),\n",
    "        annot=True,\n",
    "        square=True,\n",
    "        cbar=False,\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=False,\n",
    "        yticklabels=False,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "17072abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy\n",
      "\n",
      " [['*' 'LEFT' 'LEFT' 'LEFT']\n",
      " ['UP' 'LEFT' 'RIGHT' 'DOWN']\n",
      " ['RIGHT' 'UP' 'LEFT' 'DOWN']\n",
      " ['UP' 'RIGHT' 'RIGHT' '*']]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAFVBJREFUeJzt2wt0lOWdx/HfMLmQCyH3pIQQLhFKXVC5R0UuhaKw3kBdsVXU00qt0tbanoJ1URG0HJAVBLwvrVotC7USRCh1UUBboqAcMEDALpcoQiAEQu632ZNh+WPqdolL4CXPfD/nzJk8kxfO/8CbfOedZ8YXCAQCAgBAUhuvBwAAnD+IAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMGFqpqhL7m3uoWgBcX2HeD1CyOnbL8vrEULKvLG9vB4h5GSnRp32GK4UAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAABMmh0286QrdN+HbSkuK09adn+tnM5doY/5er8dy1ug+GZowpKt6ZyUoMTZSwx9ZrfzCY16P5Sx/G59u65+h/p3ilR4XqfKaem3+rFSL8gp1pKLW6/GcMX/2dK1ctlQ/mPRzXXfT9/7hcSv++B96640lOnhgf3Cd1aWbxt9+l/oNulytibNXCjd8p49m3n+9Zjy7Ujm3zNSWnZ8rd+E9SkmI9Xo0Z0VH+JW367Cm/2Gr16OEhMiwNspOidFrH+3XpKX5mv6nXeoY31YPXdnd69Gc8Zd1a7Qjf4uSklNOe2xyappu/+GPNfeFVzX3+VfVu09/PTrlp9q7+1O1Js5G4cffG65Fr/9FL+du0I7/OqBJM36vyqoaTbgux+vRnLV0wz7NeXO71m076PUoIaGipl6/erNA6/92RJ8fq1JBUbkWvrdXF6TGKCU2wuvxWr3Dhw7qmSd/rV9MfUz+sNO/qDLwsiHqnzNYGZlZyuiUpQl3TVLbqGjtyG9dT5KcjEJ4mF+X9MzUmrwCeywQCATXA3p38XQ24GyKifCrIRBQWXWd16O0ag0NDXpi+oMaN36Csrpkf+0/X19fr7Vvr1JVVaV6XthbrYmTewrJCbEKC/Or6MjxJo8XFZeqR+c0z+YCzqZwv093DMrU2k+LVVnb4PU4rdrS3y2S3+/XNTfc8rX+3J6/7dL9d9+mmpoaRUVF6cEZc9SpSze1Jk5GAWffuIGdNOvWvrYeP3d9cD8BZ8/QC5I06YrOtp66okD5B8ps03nKyGz5GjdG1+3xcMrW553VK4KbySc9PPMpLVv6qua9+Jp8vsZ/0ebL6NRZT/37YpWXl+n9d97WnBlTNfOpF1pVGJyMwuGSMtXV1Ss1sV2Tx1OT4nSguNSzuVyyavN+bdpdbOsDJZWezhMK8vaUqODgiQg0Ki6v+VIQuik1NlJTlu/gKuFrGnj5UPX4Vi9bv/fOn3Ws5Ihuv+Eqe6yhvl4vLpijZUt+p0VLVv7Dvys8PFwdOnYKfn1Bj29p5478YGAm/eJf1Vo4GYXaunp9vL1Qwwb20PJ3twQfayz+sAHd9czidV6P54Ty6jqVF/G69bnU+Mu+sra6yWMng9ChfVtNzt2h4+wlfG3R0THB20lXXjNOAy4b0uSYqfffrWGj/lkjR1/7tf7uQKBBtTUn4t1aOBmFRvNeWaPnp92qTdv2aeMne3TvLcMUHRWpl5Zt8Ho0Z8XHhCsjMVrp8VHBdXb6iSu1omNVOlTa9JcZzlxjEB4Yma3slGg9vHKn/D6fEqLCg99rjENdQ8DrEVuluPbxwduXNb77KCExSR07nXr57oGf3KWcK4br6nE3B9e/eWae+g26TClp6aqsqNC7f16prR9v1KNPLFRr4mwUlq7+KLjhPPXuMUpLaqctBZ/r2nsWfGXzGS1n1EUdNO/OAbZ+buKJt//Oys3X7NxtHk7mpqSYcOV0SQh+veDGUy9/NPpl7nZt3c+5fjZ9sb9QpcdKbH306BE9MeNBHSk+rJiYWHXu1j0YhEv6t663wfsCje/VbIaoS+49+9PAxPVtevmKs69vvyyvRwgp88Y2DRnOvuzUE1fxIfc5BQDA/w9RAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAIwvEAgE1Axp31/SnMPQQvr2y/J6hJAzpleq1yOElBVbi7weIeS89cMBpz2GKwUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAhMlho/tkaMKQruqdlaDE2EgNf2S18guPeT2Wk/xtfLqtf4b6d4pXelykymvqtfmzUi3KK9SRilqvx3PWhjde1q4P3tXxI4fkDwtXala2csbeofRu3/R6NOf4Q+Qcd/pKITrCr7xdhzX9D1u9HsV5kWFtlJ0So9c+2q9JS/M1/U+71DG+rR66srvXozktIT1DQ757j7477VndMOUJtUtO1xtzpqii9KjXozknMkTOcaevFJZu2Be8z0yK9noU51XU1OtXbxY0eWzhe3s1d9yFSomN0KGyGs9mc1mPQcObrAfffJe2rV+l4s92K/pbl3g2l4sqQuQcd/pKAd6KifCrIRBQWXWd16OEhPq6WuWvfUsRUTFKzuzq9TghIcbBc9zpKwV4J9zv0x2DMrX202JV1jZ4PY7Tdm/eoFXPPq7ammrFtE/U9T9/XFHt2ns9lvPCHT3HnYnCuIGdNOvWvrYeP3d9cD8BZ8fQC5I06YrOtp66okD5B8psQ27KyGz5JM1ft8fDKd2y469r9M5Lc219zX3TldG9lzr2vFjjH16oyrJS5a9dqZVPz9BND85TdFy8p/O2dkND9Bx3JgqrNu/Xpt3Ftj5QUunpPK7L21OigoMnfkAaFZfXfOmHpZtSYyM1ZfkOp55Bea3rxYOU3rWHrWMTkoP34ZFtFZ+WEbx9o1tP/XbyHcpfv0r9x9zs4bStX16InuPORKG8uk7lRe68rne+a/xBqKytbvLYyR+WDu3banLuDh136HXW80FEVHTwdjqBQED1te68RdIrlSF6jjsThf9NfEy4MhKjlR4fFVxnp7cL3hcdq9Kh0qb/2TgzjT8sD4zMVnZKtB5euVN+n08JUeHB7zX+4NQ1BLwe0Tm11VX68M1X1eXinOBeQlVZqbasyVV5yWFd0H+w1+M5xx8i57jTURh1UQfNu3OArZ+bmBO8n5Wbr9m52zyczD1JMeHK6ZIQ/HrBjb2afO+Xudu1df9xjyZzl69NG5V88Zm2v/9ocD8hKqadUrt0D35eISnj1GvhaBlJIXKO+wKN15rNkPb9JWd/Gpi+/bK8HiHkjOmV6vUIIWXF1iKvRwg5b/3w1JPkf4TPKQAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAADGFwgEAmqGzfuON+cwtJD1hYe9HiHkDM5M9nqEkDJq2iqvRwg5B1+48bTHcKUAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAmDCFiOeffExvr3hdt939M40Ze4vX4zgp742XteuDtSo7ckj+sHClZGVr0Njbld7tm16PFhI4x8++0X0yNGFIV/XOSlBibKSGP7Ja+YXH5JKQuFL44L13tGv7J0pISvF6FKfFp3fUkO/+SOOnPaOxU2YrLjlNuXMeUGXpUa9Hcx7n+LkRHeFX3q7Dmv6HrXKV81E4crhIixbM0qQpjyosLGQujDzRY9AwZV7YR+1Tv6GkjM66/Oa7VFNZocOf7fZ6NKdxjp87Szfs05w3t2vdtoNyldNRaGho0PyZU3X1jbcqs3M3r8cJKfV1tfpk7UpFRMUoObOr1+M4i3McLc3ppxXLFv9W/jZ+XXX9zV6PEjJ2b87T6mcfV21NtWLaJ+ranz+mqHbtvR7LWZzjaGnORGH9f64MbrSdNHn6k1r5x9/r1wtfkc/n83Q2FxX8dY3efWmera++b7o6dP8ndex5kf7l4YWqKjum/LUrterpx3Tjg3MVHRfv6bwu4Bw/t8YN7KRZt/a19fi564P7Ca7zBQKBQHMO3LzvuM5nlRXlOlZyxNZ/Xfe2Fi9aKJ/v1CtkDQ318rVpo+SUNM1/ZbnOZ+sLz++Tr3GvoOJLG8ixCUkKi4j8ynEvT75TPQd/R/3GnP/PZAdnJut85to5PmraKp3PYiLDlNL+1Dl9oKRSVbUNwa8zk6K1ceaYVvfuo4Mv3Bg6VwpR0THB20kjxlyvvoMGNznmsSmTdMWI0Ro66moPJnRLRFR08HY6jc856mtrz8lMruMcP7fKq+tUXlSnUONMFP5eu7j44O3LGt+Z0T4xSR0yO3s2l6tqq6u08c3X1OXiQYpun6iqslJtXbNc5SWHld2/6S8utAzO8XMvPiZcGYnRSo+PCq6z09sF74uOVelQabVc4GwUcG41vmRR8kWhdrz/tirLStU2pp3SunQPfl6h8e2pgAtGXdRB8+4cYOvnJuYE72fl5mt27ja5wJk9Bdec73sKLjrf9xRcc77vKbioOXsKTn9OAQDw9RAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwPgCgUBAzVBV15yj0FLGvfiB1yOEnI0f7vV6hJBSummt1yOEnMqP55/2GK4UAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCACZPD/vWBycpd9scmj1162eV6+rkXPZvJVf42Pt3WP0P9MuOVHhep8pp6bf68VL/JK9SRilqvx3PW6D4ZmjCkq3pnJSgxNlLDH1mt/MJjXo/lrIk3XaH7JnxbaUlx2rrzc/1s5hJtzN8rlzgdhUaXXT5Y06Y/buuIiAhP53FVZFgbdUuO0Wsf7dfu4grFRvo18dIsTb2yu376er7X4zkrOsKvvF2HlbvxM82Z0M/rcZx2w3f6aOb912vSjMX68JM9uveWYcpdeI8uum6aDpWUyRXOR6ExAskpKV6P4byKmno9uKKgyWNPv79XT469UCmxETpUVuPZbC5bumFf8D4zKdrrUZz34+8N16LX/6KXczcE15Nm/F5XDb5QE67L0exFf5YrnN9T2PjhBxo6OEfXjBml6dMe0tGjJV6PFDJiIvxqCARUVl3n9SjAGQkP8+uSnplak3fqiU8gEAiuB/TuIpc4faVw6eWD9e0RI5XRsaMKCwv11JNz9KOJP9DLry6W3+/3ejynhft9umNgptZ+WqzK2gavxwHOSHJCrMLC/Co6crzJ40XFperROU0ucSYKK97M1aMPP2Trhc8+r6tGj7H1Bd17qHv3Hhpz5Yjg1cPAQTkeTeqGodlJuveKzrZ+6K0C5R8os03nKSOyg18vWL/HsxldM25gJ826ta+tx89dH9xPAFqSM1EYOmy4evW6yNapaV+td8fMTCUkJGjfvr1E4Qzl7S1RwdJTm2vF5TUWhMkjuimlXaQeWL6Dq4QWtGrzfm3aXWzrAyWVns4TSg6XlKmurl6pie2aPJ6aFKcDxaVyiTNRiImJDd7+LwcPHNDRo0eVkszG85lq/GVfWVvd5LGTQejQvq2mLN+h4+wltKjy6jqVF/Fv6oXaunp9vL1Qwwb20PJ3twQf8/l8Gjagu55ZvE4ucSYKf6+ivFzPPD1fI0aOUlJysj4rLNS/PTFLmZ2ygnsNaFmNQXhgZLa6JUfrkZU75ff5lBAVHvxeYxzqGgJej+ik+JhwZSRGKz0+KrjOTj/xTLboWJUOlTaNNs7MvFfW6Plpt2rTtn3a+D9vSY2OitRLy068G8kVzkahjd+vnQU7lbvsDR0vPa7U1FTlXHqZ7pn0Ez6rcBYkRYdrUOeE4Nfzb+zV5HuTc7dr6xdNN+jQMkZd1EHz7hxg6+cmnnhZdFZuvmbnbvNwMvcsXf1RcMN56t1jlJbUTlsKPte19yz4yuZza+cLNL6vqhmquGo9p8a9+IHXI4ScjR+69cnU813pprVejxByKj+ef9pjnP+cAgCg+YgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYHyBQCBwagkACGVcKQAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAAdNJ/AxX1cbbNZOUzAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run mc policy control GLIE\n",
    "V_pi, policy = GLIE(env, discount_factor=1.0, episode_count=10000)\n",
    "\n",
    "action_labels = {0:\"UP\", 1:\"RIGHT\", 2: \"DOWN\", 3:\"LEFT\"}\n",
    "# print policy\n",
    "optimal_actions = [action_labels[policy[s]] for s in range(env.nS)]\n",
    "optimal_actions[0] = \"*\" \n",
    "optimal_actions[-1] = \"*\" \n",
    "\n",
    "print(\"policy\\n\\n\",np.array(optimal_actions).reshape(env.shape))\n",
    "\n",
    "# print state values\n",
    "grid_print(V_pi.reshape(env.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-training-2025-codes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
